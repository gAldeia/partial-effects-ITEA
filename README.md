Measuring Feature Importance of Symbolic Regression Models Using Partial Effects
=====

Recently, we studied how the symbolic regression algorithm named _Interaction-Transformation Evolutionary Algorithm_ (ITEA) could benefit from using the Partial Effects to find variable importances and compared the performance with SHAP, LIME, and ELI5.

This repository contains all experiment scripts, data sets, ITEA implementation, and results used for the paper _Measuring Feature Importance of Symbolic Regression Models Using Partial Effects_, submitted for the 2021 GECCO.

> **Paper abstract: One of the objectives of explainable AI is to explain a particular prediction by quantifying each input variable's importance to the decision process. Because we cannot extract this information from the black-box model, this field proposed different model-agnostics explainers such as LIME, SHAP, and ELI5. Upon requesting an explanation for a given prediction, they part from the same principle of creating a local white-box model from the neighborhood of this prediction capable of measuring this importance.
As argued by some researchers, a better approach is to fit a white-box model from the start. A notable white-box model for regression is the Symbolic Regression, which searches for an analytical model approximating the input data. Even though this model is often associated with interpretability, few works explore this property. This paper will evaluate different model agnostic explainers and compare them with a model-specific explainer for symbolic expressions. We investigate how the global regressor affects the model-agnostic explainers and whether the model-specific explainer can give good explanations even when the Symbolic Regressor does not return the ground-truth expression. The results show that the global regressor does not affect the explainer and that the model-specific approach is robust w.r.t. variations of the generated expression.**

Please, cite us as:
```
@INPROCEEDINGS{MeasuringFeatureImportanceITEA,
    numpages={9},
    year = 2021,
    month = {jul},
    publisher = {{ACM}},
    author = {Guilherme Seidyo Imai Aldeia and Fabrício Olivetti de França},
    title = {Measuring Feature Importance of Symbolic Regression Models Using Partial Effects},
    booktitle = {2021 {ACM} Genetic and Evolutionary Computation Conference ({GECCO})}
}
```

Folder structure
-----


```
.
├── datasets
├── docs 
├── results
│   ├── figures
│   ├── tabular_processed
│   └── tabular_raw      
└── src
    ├── analysis
    ├── experiments      
    └── itea

```

* ```datasets```: folder with all data sets used;
* ```docs```: simple markdown files documenting some aspects of this repository;
* ```results/figures```: pdf figures generated by the analysis scripts;
* ```results/tabular_processed```: processed and merged final tables;
* ```results/tabular_raw```: raw result files generated from the experiment scripts;
* ```src/analysis```: scripts to analyze the data and generate the figures;
* ```src/experiments```: scripts for performing the experiments
* ```src/itea```: source code implementation for the ITEA algorithm, as used in the paper.



Dependencies
-----

Since the libraries can be updated in the future and present compatibility errors, below are the version of the libraries utilized in the experiments.

| Library     | Version  |
|:------------|:--------:|
| numpy       | 1.19.1   |
| pandas      | 1.1.0    |
| shap        | 0.36.0   |
| lime        | 0.2.0.1  |
| filelock    | 3.0.12   |
| autograd    | 1.3      |
| scipy       | 1.5.2    |
| eli5        | 0.10.1   |
| scikit      | 0.23.2   |
| statsmodels | 0.11.1   |
| typing      | 3.7.4.1  |


License
-----

This source code is distributed under the GNU GENERAL PUBLIC LICENSE.

Acknowledgments
-----
This project is funded by Fundação de Amparo À Pesquisa do Estado de São Paulo (FAPESP), grant number 2018/14173-8 and Fundação Universidade Federal do ABC.